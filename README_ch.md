# CuteGPT

[[Readme ENG](README.md)][[Readme ZH](README_ch.md)]

CuteGPT是[复旦大学知识工场实验室](http://kw.fudan.edu.cn/)推出的一个支持中英双语的开源对话语言模型，基于Llama模型结构进行改进和扩展，规模为13B（130亿）参数，可以在单张3090显卡上进行int8精度的推理。CuteGPT基于Llama模型，修改了中文词表并进行了大量的预训练，提高了对中文的理解能力，后续经过对话指令微调，提升了模型对指令的理解能力。

## 开放参数

| Huggingface                       | 描述                                      |
| --------------------------------- | ----------------------------------------- |
| XuYipei/kw-cutegpt-13b-base       | 基于原版Llama扩充中文词表并进行二次预训练 |
| XuYipei/kw-cutegpt-13b-ift        | 全量参数指令微调                          |
| Abbey4799/kw-cutegpt-13b-ift-lora | 基于lora指令微调                          |

## 评测结果

### C-eval

#### Zero-shot

| Model                          | STEM           | Social Science | Humanities     | Other          | Average        |
| ------------------------------ | -------------- | -------------- | -------------- | -------------- | -------------- |
| GPT-4                          | 65.2           | 74.7           | 62.5           | 64.7           | 66.4           |
| ChatGPT                        | 49             | 58             | 48.8           | 50.4           | 51             |
| Claude-v1.3                    | 48.5           | 58.6           | 47.3           | 50.1           | 50.5           |
| Bloomz-mt-176B                 | 39.1           | 53             | 47.7           | 42.7           | 44.3           |
| GLM-130B                       | 36.7           | 55.8           | 47.7           | 43             | 44             |
| Claude-instant-v1.0            | 38.6           | 47.6           | 39.5           | 39             | 40.6           |
| ChatGLM-6B                     | 33.3           | 48.3           | 41.3           | 38             | 38.9           |
| LLaMA-65B                      | 32.6           | 41.2           | 34.1           | 33             | 34.7           |
| **CuteGPT-13B-ift-lora** | **30.9** | **39.3** | **37.9** | **32.4** | **34.3** |
| MOSS                           | 31.6           | 37             | 33.4           | 32.1           | 33.1           |
| Chinese-Alpaca-13B             | 27.4           | 39.2           | 32.5           | 28             | 30.9           |
| Chinese-LLaMA-13B              | 28.8           | 32.9           | 29.7           | 28             | 29.6           |

#### Five-shot

| Model                          | STEM           | Social Science | Humanities     | Other          | Average        |
| ------------------------------ | -------------- | -------------- | -------------- | -------------- | -------------- |
| GPT-4                          | 67.1           | 77.6           | 64.5           | 67.8           | 68.7           |
| ChatGPT                        | 52.9           | 61.8           | 50.9           | 53.6           | 54.4           |
| Claude-v1.3                    | 51.9           | 61.7           | 52.1           | 53.7           | 54.2           |
| Claude-instant-v1.0            | 43.1           | 53.8           | 44.2           | 45.4           | 45.9           |
| GLM-130B                       | 34.8           | 48.7           | 43.3           | 39.8           | 40.3           |
| Bloomz-mt-176B                 | 35.3           | 45.1           | 40.5           | 38.5           | 39             |
| LLaMA-65B                      | 37.8           | 45.6           | 36.1           | 37.1           | 38.8           |
| **CuteGPT-13B-ift-lora** | **33.3** | **43.1** | **40.4** | **35.5** | **37.1** |
| **CuteGPT-13B-base**     | **33.3** | **42**   | **39.7** | **33.8** | **36.4** |
| ChatGLM-6B                     | 30.4           | 39.6           | 37.4           | 34.5           | 34.5           |
| Chinese LLaMA-13B              | 31.6           | 37.2           | 33.6           | 32.8           | 33.3           |
| MOSS                           | 28.6           | 36.8           | 31             | 30.3           | 31.1           |
| Chinese Alpaca-13B             | 26             | 27.2           | 27.8           | 26.4           | 26.7           |

#### C-eval Hard

| Model                          | Zero-shot      | Five-shot      |
| ------------------------------ | -------------- | -------------- |
| GPT-4                          | 53.3           | 54.9           |
| Claude-v1.3                    | 37.6           | 39             |
| ChatGPT                        | 36.7           | 41.4           |
| Claude-instant-v1.0            | 32.1           | 35.5           |
| Bloomz-mt                      | 30.8           | 30.4           |
| GLM-130B                       | 30.7           | 30.3           |
| LLaMA-65B                      | 29.8           | 31.7           |
| **CuteGPT-13b-ift-lora** | **28.4** | **28.9** |
| **CuteGPT-13b-base**     | **N/A**  | **27.6** |
| ChatGLM-6B                     | 29.2           | 23.1           |
| MOSS                           | 28.4           | 24             |
| Chinese-LLaMA-13B              | 27.5           | 27.3           |
| Chinese-Alpaca-13B             | 24.4           | 27.1           |

### XieZhi

## 推理性能

## CuteGPT使用示例

| 任务类型         | 指令                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | 全量微调                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | lora                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ---------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 规划 (Few-shot)  | 你是一个知识图谱访问代理，你的任务是编写Python代码，使用内置的Python函数和下面给出的函数来获取用户查询相关的信息：<br>1. get_entity_info(entity_aliases)：获取一个实体的百科信息。返回'result'（实体信息或None）和'message'（描述函数调用和结果）。<br>2. find_entity_or_value(entity_aliases, relation_aliases)：找到实体或值以回答事实查询。返回'result'（实体名列表或属性值或None）和'message'（描述函数调用和结果）。<br>3. find_relationship(entity1_aliases, entity2_aliases)：预测两个实体之间的关系。返回'result'（关系或None）和'message'（描述函数调用和结果）。<br>===<br>请遵循以下规则：<br>1. 你的工作是获取相关知识，而不是直接回答查询。<br>2. 只使用内置的Python函数和提供的函数。<br>3. 在调用函数时，对实体和关系的别名进行释义和列举候选，按别名频率排序。<br>4. 在使用find_entity_or_value时，使用清晰的关系。对于模糊或广泛的关系查询，使用get_entity_info。<br>5. 通过富有逻辑的代码处理多步或嵌套的查询。<br>6. 以JSON格式响应。<br>7. 你需要一步一步思考并给出三个部分的结果：need_knowledge, thought, code。首先，你需要判断该问题是否需要知识。若是，你需要先给出一个想法，规划如何完成该查询。然后，你需要将想法转化为可执行的代码。<br>8. 所有函数调用的'messages'都记录在名为'messages'的字符串中，这是search()的返回值。<br>9. 在'messages'字符串中添加必要的解释。<br>输出格式：<br>{<br>    "need_knowledge": "<是或否>",<br>    "thought": "<你的思考过程>",<br>    "code": "def search():\n\tmessages = ''\n\t<你的代码>\n\treturn messages\n",<br>}<br>===示例===<br>Input："提出进化论的科学家是谁？"<br>Output：<br>{<br>    "need_knowledge": "是",<br>    "thought": "这个问题想问的是谁提出了进化论，我需要查询进化论的提出者是谁。'提出者'关系可能的表达方式有'提出'、'提出者'、'发现'。",<br>    "code": "def search():\n\tmessages = ''\n\tproposer, msg = find_entity_or_value(entity_aliases = ['进化论'], relation_aliases = ['提出', '提出者', '发现'])\n\tmessages += msg\n\treturn messages\n"<br>}<br>2.<br>Input："有哪些科幻小说和《三体》是同一个作者？"<br>Output：<br>{<br>    'need_knowledge': 'yes', <br>    'thought': "这个问题想要知道和《三体》是同一个作者的科幻小说都有哪些。首先，我需要找到《三体》的作者，这个关系可能被表达为'作者'、'创作'、'写作'。然后，我需要找到这个作者创作的其他科幻小说，这个关系可能被表达为'作品'、'创作'、'写作'。", <br>    'code': "def search():\n\tmessages = ''\n\tauthor, msg = find_entity_or_value(entity_aliases = ['三体'], relation_aliases = ['作者', '创作', '写作'])\n\tmessages += msg\n\tif author:\n\t\tworks, msg = find_entity_or_value(entity_aliases = author, relation_aliases = ['作品', '创作', '写作'])\n\t\tmessages += msg\n\treturn messages\n", <br>}<br>===<br>输入: 《择天记》的男主角是谁？他还有什么代表作品？ | {<br>    "need_knowledge": "是",<br>    "thought": "这个问题想问的是《择天记》的男主角是谁，以及他有哪些代表作品。'男主角'关系可能的表达方式有'主角'、'男主角'、'主演'。'代表作品'关系可能的表达方式有'作品'、'代表作品'、'作品名称'。",<br>    "code": "def search():<br>        messages = ''<br>        main_character, msg = find_entity_or_value(entity_aliases = ['择天记'], relation_aliases = ['男主角', '主角', '主演'])       <br>        messages += msg <br>        representative_works, msg = find_entity_or_value(entity_aliases = main_character, relation_aliases = ['代表作品', '作品', '代表作品', '作品名称'])<br>        messages += msg <br>        return messages <br>",<br>}                                                                                                                                                                  | {<br>    "need_knowledge": "是",<br>    "thought": "这个问题想问的是《择天记》的男主角是谁，以及他有什么代表作品。首先，我需要找到《择天记》的男主角，这个关系可能被表达 为'主角'、'主演'、'演员'等。其次，我还需要找到他的代表作品，这个关系可能被表达为'作品'、'创作'、'写作'等。",<br>    "code": "def search():<br>        messages = ''<br>        actor, msg = find_entity_or_value(entity_aliases = ['择天记'], relation_aliases = ['主角', '主演', '演员'])<br>        messages += msg <br>        if actor:<br>                works, msg = find_entity_or_value(entity_aliases = actor, relation_aliases = ['作品', '创作', '写作'])<br>                messages += msg <br>        return messages <br>"<br>}                                                                |
| 规划 (Zero-shot) | 你是一个知识图谱访问代理，你的任务是编写Python代码，使用内置的Python函数和下面给出的函数来获取用户查询相关的信息：<br>1. get_entity_info(entity_aliases)：获取一个实体的百科信息。返回'result'（实体信息或None）和'message'（描述函数调用和结果）。<br>2. find_entity_or_value(entity_aliases, relation_aliases)：找到实体或值以回答事实查询。返回'result'（实体名列表或属性值或None）和'message'（描述函数调用和结果）。<br>3. find_relationship(entity1_aliases, entity2_aliases)：预测两个实体之间的关系。返回'result'（关系或None）和'message'（描述函数调用和结果）。<br>===<br>请遵循以下规则：<br>1. 你的工作是获取相关知识，而不是直接回答查询。<br>2. 只使用内置的Python函数和提供的函数。<br>3. 在调用函数时，对实体和关系的别名进行释义和列举候选，按别名频率排序。<br>4. 在使用find_entity_or_value时，使用清晰的关系。对于模糊或广泛的关系查询，使用get_entity_info。<br>5. 通过富有逻辑的代码处理多步或嵌套的查询。<br>6. 以JSON格式响应。<br>7. 你需要一步一步思考并给出三个部分的结果：need_knowledge, thought, code。首先，你需要判断该问题是否需要知识。若是，你需要先给出一个想法，规划如何完成该查询。然后，你需要将想法转化为可执行的代码。<br>8. 所有函数调用的'messages'都记录在名为'messages'的字符串中，这是search()的返回值。<br>9. 在'messages'字符串中添加必要的解释。<br>输出格式：<br>{<br>    "need_knowledge": "<是或否>",<br>    "thought": "<你的思考过程>",<br>    "code": "def search():\n\tmessages = ''\n\t<你的代码>\n\treturn messages\n",<br>}<br>===<br>输入: 《择天记》的男主角是谁？他还有什么代表作品？                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | {<br>    "need_knowledge": True,<br>    "thought": "要回答这个问题，我们需要查找《择天记》的男主角以及他的代表作品。我们可以使用get_entity_info函数来查找男主角的百科信息，并使用find_entity_or_value函数来查找他的代表作品。",<br>    "code": "def search():<br>        entity_aliases = ['择天记', '男主角']<br>        relation_aliases = []<br>        messages = ''<br>        result = get_entity_info(entity_aliases)<br>        if result['result'] is not None:<br>                entity_name = result['result']<br>        else:<br>                entity_name = None <br>        result = find_entity_or_value(entity_aliases, '男主角')<br>        result = find_entity_or_value(entity_aliases, '代表作品')<br>        if result['result'] is not None:<br>                representative_works = result['result']<br>        else: | {<br>    "need_knowledge": "是",<br>    "thought": "根据题目，我们知道这是一个关于小说《择天记》的问题。因此，我们可以通过查找小说中的人物角色来解决这个问题。`<br><br>`首先，我们需要了解小说的主要内容。根据百度百科介绍，《择天记》是一部由唐家三少所著的网络玄幻小说，讲述了陈长生与徐有容之间的爱情故事 。其中，陈长生是小说的主角之一。`<br><br>`其次，我们可以通过搜索小说中的人物角色来确定男主角的身份。根据小说的内容，我们可以得知陈长生是小说的男主角之一。此外，小说还提到了其 他一些主要人物，如徐有容、南客等。`<br><br>`最后，我们可以通过搜索这些主要人物的角色来获得他们的作品。例如，陈长生的作品包括《神墓》、《斗罗大陆》等；而徐有容的作品则包括《大主 宰》等。`<br><br>`综上所述，答案为：<br>- 《择天记》的男主角是陈长生。<br>- 陈长生还有其他的代表作品，如《神墓》、《斗罗大陆》等。 |
| 复杂抽取         | 从句子中提取公司的基本信息。需要提取公司名称、成立时间、公司类型、资产总额、经营总收入、主要销售区域、主要产品等信息。其中的输出格式为输出格式为字典，包含以下键值对：<br>{<br>    "公司名称": "",<br>    "成立时间": "",<br>    "公司类型": "",<br>    "资产总额": "",<br>    "经营总收入": "",<br>    "主要销售区域": "",<br>    "主要产品": ""<br>}`<br><br>`北京京煤集团有限责任公司是按现代企业制度于2001年初组建的国有独资大型煤炭企业集团。现拥有资产总额149亿元，2008年实现经营总收入93亿元。它所产无烟煤畅销京津、华北、东北、华南及亚、欧、北美、南美四大洲，是中国最大的优质无烟煤生产和出口基地之一。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | {<br>    "公司名称": "北京京煤集团有限责任公司",<br>    "成立时间": "2001年",<br>    "公司类型": "国有企业",<br>    "资产总额": "149亿元",<br>    "经营总收入": "93亿元",<br>    "主要销售区域": "京津、华北、东北、华南及亚、欧、北美、南美四大洲",<br>    "主要产品": "无烟煤"<br>}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | {<br>    "公司名称": "北京京煤集团有限责任公司",<br>    "成立时间": "2001年初",<br>    "公司类型": "国有独资大型煤炭企业集团",<br>    "资产总额": "149亿元",<br>    "经营总收入": "93亿元",<br>    "主要销售区域": "京津、华北、东北、华南及亚、欧、北美、南美四大洲",<br>    "主要产品": "中国最大的优质无烟煤生产和出口基地之一"<br>}                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
|                  | 从给定的句子中提取特定的元素。需要提取的元素类型为人名、性别、职务、任职时间、荣誉称号等，其中人名需要包括姓和名，职务需要包括级别和具体名称。输出格式为一个字典，包含以下键值对：<br>   - "姓名"：人名，字符串类型；<br>   - "性别"：性别，字符串类型；<br>   - "职务"：职务，字符串类型；<br>   - "任职时间"：任职时间，字符串类型；<br>   - "荣誉称号"：荣誉称号，字符串类型。`<br><br>`彭安荣，男，现任重庆市人民检察院党组成员、副检察长（正厅级）。历任重庆市江津县支坪乡、洛璜镇党委书记、重庆市江津市检察院党组书记，1998年3月任重庆市渝北区检察院检察长，2003年2月22日任重庆市人民检察院检察委员会委员、检察员、党组成员、职务犯罪侦查局局长，2005年5月27日任重庆市人民检察院副检察长。被最高人民检察院授予“模范检察干部”称号。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | {"姓名": "彭安荣", "性别": "男", "职务": "重庆市人民检察院党组成员、副检察长（正厅级）", "任职时间": "1998年3月-2005年5月27日", "荣誉称号": "模范检察干部"}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | {<br>    "姓名": "彭安荣",<br>    "性别": "男",<br>    "职务": {<br>        "级别": "正厅级",<br>        "具体名称": "重庆市人民检察院党组成员、副检察长"<br>    },<br>    "任职时间": "1998年3月至今",<br>    "荣誉称号": "模范检察干部"<br>}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
|                  | 在以下船舶相关的文本中，请抽取出船舶中所有的属性和其对应的属性值，并以键值对的形式进行输出。`<br><br>`5月10日上午,由浙江增洲造船有限公司为舟山港兴港海运有限公司建造的第二艘45000DWT“舟港海8”散货船顺利交付。据悉,该船设计结构吃水10.5m,载重量为46000吨,载货量为45000吨,于2011年4月开始建造,2012年1月8日下水。这是该公司今年交付的第三艘船,体现了其打造江海联运船舶的丰富经验。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 船舶属性：<br>- 船名：舟港海8 <br>- 载重量：46000吨 <br>- 载货量：45000吨 <br>- 设计结构吃水：10.5米 <br>- 建造时间：2011年4月开始建造，2012年1月8日下水 <br>舟山港兴港海运有限公司的船舶属性：<br>- 公司名称：舟山港兴港海运有限公司 <br>- 建造船厂：浙江增洲造船有限公司                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 船舶属性:<br>- 制造商: 浙江增洲造船有限公司 <br>- 船名: “舟港海8”散货船 <br>- 载重量: 46000吨 <br>- 载货量: 45000吨 <br>- 设计结构吃水: 10.5米 <br>- 建造时间: 2011年4月至2012年1月8日 <br>- 交付日期: 5月10日上午 <br>- 用途: 江海联运船舶                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
|                  |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
|                  |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
|                  |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |

## 使用方式

### 安装依赖

```bash
conda create -n cutegpt python=3.7
conda activate cutegpt
pip install -r requirements.txt 
```

### 使用示例

```python
from transformers import LlamaForCausalLM, LlamaTokenizer
from peft import PeftModel
import torch
```

- 推理时的prompt模版

```bash
overall_instruction = "你是复旦大学知识工场实验室训练出来的语言模型CuteGPT。给定任务描述，请给出对应请求的回答。\n"
def generate_prompt(query, history, input=None):
    prompt = overall_instruction
    for i, (old_query, response) in enumerate(history):
        # 多轮对话需要跟训练时保持一致
        prompt += "问：{}\n答：{}\n".format(old_query, response)
    prompt += "问：{}\n答：".format(query)
    return prompt
```

- 加载模型、分词器，此处采用lora版本的checkpoint、8bit量化

```python
model_name = "XuYipei/kw-cutegpt-13b-base"
LORA_WEIGHTS = "Abbey4799/kw-cutegpt-13b-ift-lora"
tokenizer = LlamaTokenizer.from_pretrained(LORA_WEIGHTS)
model = LlamaForCausalLM.from_pretrained(
    model_name,
    load_in_8bit=True,
    torch_dtype=torch.float16,
    device_map="auto",
)
model.eval()
model = PeftModel.from_pretrained(model, LORA_WEIGHTS)
device = torch.device("cuda")
```

- 推理

```python
history = []
queries = ['请推荐五本名著，依次列出作品名、作者','再来三本呢？']
memory_limit = 3 # the number of (query, response) to remember
for query in queries:
    prompt = generate_prompt(query, history)
    print(prompt)

    input_ids = tokenizer(prompt, return_tensors="pt", padding=False, truncation=False, add_special_tokens=False)
    input_ids = input_ids["input_ids"].to(device)

    with torch.no_grad():
        outputs=model.generate(
                input_ids=input_ids,
                top_p=0.8,
                top_k=50,
                repetition_penalty=1.1,
                max_new_tokens = 256,
                early_stopping = True,
                eos_token_id = tokenizer.convert_tokens_to_ids('<s>'),
                pad_token_id = tokenizer.eos_token_id,
                min_length = input_ids.shape[1] + 1
        )
    s = outputs[0][input_ids.shape[1]:]
    response=tokenizer.decode(s)
    response = response.replace('<s>', '').replace('<end>', '').replace('</s>', '')
    print(response)
    history.append((query, response))
    history = history[-memory_limit:]
```

可以直接运行以下脚本进行推理：

```python
CUDA_VISIBLE_DEVICES=0 python inference.py
```

## 微调

### 数据格式

数据以 `.pkl`的形式存储，可以用以下代码查看数据：

```python
import pickle
import random
file = 'data/test/ift_data.pkl'
with open(file, "rb") as f:
    datas = pickle.load(f)
print(len(datas))
print(random.sample(datas,3))
```

数据由二维数组保存，`len(datas)`为样本的数量，`len(data[i])`代表第 `i`个样本的对话轮数，其中每轮对话由 `instruction`、`input`、`output`三个键值构成。示例如下：

```python
[[{'instruction': '请帮我生成一首诗。', 'input': '', 'output': '好的，请给我一些关键词来启发诗歌的创作。'},
  {'instruction': '月亮、海浪、夜晚。',
   'input': '',
   'output': '心中的孤独由天空掩盖，\n夜幕笼罩下，海浪轻扬，\n月光照亮着沙滩，\n让我不再孤单。'}],
 [{'instruction': '根据给定的数据集，训练一个能够对垃圾邮件进行分类的模型。\n提供垃圾邮件和非垃圾邮件两类的数据集。',
   'input': '',
   'output': '要训练一个能...'}]]
```

### 微调代码

预处理数据，将数据拼接成多轮对话的格式，并编码得到 `input_ids`，存储下来

```bash
python code/convert_data.py \
	--tokenizer ziqingyang/chinese-llama-lora-7b \
	--max_length 2048 \
	--out_data_path data/test/
```

训练模型

```bash
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 deepspeed --master_port 12932 code/finetune.py \
    --save_steps 2000 \
    --max_epoches 4 \
    --save_name llama_lora \
    --model_path XuYipei/kw-cutegpt-13b-base \
    --dataset_type DatasetIds \
    --data_path data/test/llama_ift_data_ids.pkl \
    --max_length 2048 \
    --use_flash_attention
```

参数说明

- `model_path`：`base`模型的路径
- `dataset_type`：封装数据的 `dataset`类定义，在 `code/dataset.py`中定义
- `use_flash_attention`：是否使用flash attention加快训练、减少显存消耗
- `load_lora`：是否读取lora checkpoint继续训练。如果 `load_lora==True`，在 `load_lora_path`中定义lora checkpoint的路径

具体的 deepspeed 参数（例如 ` learning rate`、` batch size`）以及   `lora `参数（例如 ` lora rank`）见  ` code/config.py`

可以直接运行以下指令进行训练：

```
bash finetune.sh
```
