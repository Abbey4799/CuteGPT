# CuteGPT

[[Readme ENG](README.md)][[Readme ZH](README_ch.md)]

CuteGPT is an open-source conversational language model that supports both Chinese and English, developed by [Fudan University Knowledge Workshop Laboratory](http://kw.fudan.edu.cn/). It is based on the original Llama model structure, and has a scale of 13B (13 billion) parameters. It can perform int8 precision inference on a single 3090 graphics card. CuteGPT expands the Chinese vocabulary and performs pre-training on the Llama model, improving its ability to understand Chinese. Subsequently, it is fine-tuned with conversational instructions to enhance the model's ability to understand instructions.

## Open Parameters

| Huggingface                       | Description                                                                              |
| --------------------------------- | ---------------------------------------------------------------------------------------- |
| XuYipei/kw-cutegpt-13b-base       | Expand Chinese vocabulary and perform secondary pre-training based on the original Llama |
| XuYipei/kw-cutegpt-13b-ift        | Full parameter instruction fine-tuning                                                   |
| Abbey4799/kw-cutegpt-13b-ift-lora | Instruction fine-tuning based on lora                                                    |

## Evaluation

### C-eval

#### Zero-shot

| Model                          | STEM           | Social Science | Humanities     | Other          | Average        |
| ------------------------------ | -------------- | -------------- | -------------- | -------------- | -------------- |
| GPT-4                          | 65.2           | 74.7           | 62.5           | 64.7           | 66.4           |
| ChatGPT                        | 49             | 58             | 48.8           | 50.4           | 51             |
| Claude-v1.3                    | 48.5           | 58.6           | 47.3           | 50.1           | 50.5           |
| Bloomz-mt-176B                 | 39.1           | 53             | 47.7           | 42.7           | 44.3           |
| GLM-130B                       | 36.7           | 55.8           | 47.7           | 43             | 44             |
| Claude-instant-v1.0            | 38.6           | 47.6           | 39.5           | 39             | 40.6           |
| ChatGLM-6B                     | 33.3           | 48.3           | 41.3           | 38             | 38.9           |
| LLaMA-65B                      | 32.6           | 41.2           | 34.1           | 33             | 34.7           |
| **CuteGPT-13B-ift-lora** | **30.9** | **39.3** | **37.9** | **32.4** | **34.3** |
| MOSS                           | 31.6           | 37             | 33.4           | 32.1           | 33.1           |
| Chinese-Alpaca-13B             | 27.4           | 39.2           | 32.5           | 28             | 30.9           |
| Chinese-LLaMA-13B              | 28.8           | 32.9           | 29.7           | 28             | 29.6           |

#### Five-shot

| Model                          | STEM           | Social Science | Humanities     | Other          | Average        |
| ------------------------------ | -------------- | -------------- | -------------- | -------------- | -------------- |
| GPT-4                          | 67.1           | 77.6           | 64.5           | 67.8           | 68.7           |
| ChatGPT                        | 52.9           | 61.8           | 50.9           | 53.6           | 54.4           |
| Claude-v1.3                    | 51.9           | 61.7           | 52.1           | 53.7           | 54.2           |
| Claude-instant-v1.0            | 43.1           | 53.8           | 44.2           | 45.4           | 45.9           |
| GLM-130B                       | 34.8           | 48.7           | 43.3           | 39.8           | 40.3           |
| Bloomz-mt-176B                 | 35.3           | 45.1           | 40.5           | 38.5           | 39             |
| LLaMA-65B                      | 37.8           | 45.6           | 36.1           | 37.1           | 38.8           |
| **CuteGPT-13B-ift-lora** | **33.3** | **43.1** | **40.4** | **35.5** | **37.1** |
| **CuteGPT-13B-base**     | **33.3** | **42**   | **39.7** | **33.8** | **36.4** |
| ChatGLM-6B                     | 30.4           | 39.6           | 37.4           | 34.5           | 34.5           |
| Chinese LLaMA-13B              | 31.6           | 37.2           | 33.6           | 32.8           | 33.3           |
| MOSS                           | 28.6           | 36.8           | 31             | 30.3           | 31.1           |
| Chinese Alpaca-13B             | 26             | 27.2           | 27.8           | 26.4           | 26.7           |

#### C-eval Hard

| Model                          | Zero-shot      | Five-shot      |
| ------------------------------ | -------------- | -------------- |
| GPT-4                          | 53.3           | 54.9           |
| Claude-v1.3                    | 37.6           | 39             |
| ChatGPT                        | 36.7           | 41.4           |
| Claude-instant-v1.0            | 32.1           | 35.5           |
| Bloomz-mt                      | 30.8           | 30.4           |
| GLM-130B                       | 30.7           | 30.3           |
| LLaMA-65B                      | 29.8           | 31.7           |
| **CuteGPT-13b-ift-lora** | **28.4** | **28.9** |
| **CuteGPT-13b-base**     | **N/A**  | **27.6** |
| ChatGLM-6B                     | 29.2           | 23.1           |
| MOSS                           | 28.4           | 24             |
| Chinese-LLaMA-13B              | 27.5           | 27.3           |
| Chinese-Alpaca-13B             | 24.4           | 27.1           |

### XieZhi

| Models               | MMLU            | MMLU            | MMLU            | C-Eval          | C-Eval          | C-Eval          | M3KE            | Xiezhi-Spec.-Chinese | Xiezhi-Spec.-Chinese | Xiezhi-Spec.-Chinese | Xiezhi-Inter.-Chinese | Xiezhi-Inter.-Chinese | Xiezhi-Inter.-Chinese | Xiezhi-Spec.-English`` | Xiezhi-Spec.-English`` | Xiezhi-Spec.-English`` | Xiezhi-Inter.-English | Xiezhi-Inter.-English | Xiezhi-Inter.-English |
| -------------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | --------------- | -------------------- | -------------------- | -------------------- | --------------------- | --------------------- | --------------------- | ---------------------- | ---------------------- | ---------------------- | --------------------- | --------------------- | --------------------- |
|                      | 0-shot          | 1-shot          | 3-shot          | 0-shot          | 1-shot          | 3-shot          | 0-shot          | 0-shot               | 1-shot               | 3-shot               | 0-shot                | 1-shot                | 3-shot                | 0-shot                 | 1-shot                 | 3-shot                 | 0-shot                | 1-shot                | 3-shot                |
| Random-Guess         | 0.089           | 0.089           | 0.089           | 0.089           | 0.089           | 0.089           | 0.089           | 0.089                | 0.089                | 0.089                | 0.089                 | 0.089                 | 0.089                 | 0.089                  | 0.089                  | 0.089                  | 0.089                 | 0.089                 | 0.089                 |
| <100B                |                 |                 |                 |                 |                 |                 |                 |                      |                      |                      |                       |                       |                       |                        |                        |                        |                       |                       |                       |
| CuteGPT-13B-ift-lora | **0.154** | *0.092*       | 0.051           | *0.143*       | **0.191** | **0.157** | 0.103           | *0.17*             | **0.204**      | 0.143                | *0.18*              | *0.221*             | **0.202**       | **0.141**        | **0.189**        | **0.209**        | **0.174**       | **0.215**       | **0.255**       |
| chatglm2-6B          | 0.063           | 0.082           | *0.111*       | **0.145** | *0.143*       | 0.105           | **0.182** | **0.242**      | *0.191*            | **0.22**       | **0.259**       | **0.222**       | *0.165*             | 0.106                  | 0.095                  | 0.099                  | 0.096                 | *0.096*             | *0.112*             |
| chatglm-6B           | *0.099*       | **0.109** | **0.112** | 0.084           | 0.074           | *0.114*       | *0.115*       | 0.082                | 0.097                | *0.147*            | 0.104                 | 0.111                 | 0.144                 | 0.106                  | *0.12*               | *0.124*              | 0.099                 | 0.079                 | 0.097                 |
| doctorglm-6B         | 0.093           | 0.076           | 0.065           | 0.037           | 0.085           | 0.051           | 0.038           | 0.062                | 0.068                | 0.044                | 0.047                 | 0.056                 | 0.043                 | 0.069                  | 0.053                  | 0.043                  | 0.106                 | 0.059                 | 0.059                 |
| moss-base-16B        | 0.072           | 0.05            | 0.062           | 0.115           | 0.048           | 0.052           | 0.099           | 0.105                | 0.051                | 0.059                | 0.123                 | 0.054                 | 0.058                 | *0.124*              | 0.077                  | 0.08                   | *0.121*             | 0.058                 | 0.063                 |
| moss-sft-16B         | 0.064           | 0.065           | 0.051           | 0.063           | 0.062           | 0.072           | 0.075           | 0.072                | 0.067                | 0.068                | 0.073                 | 0.081                 | 0.066                 | 0.071                  | 0.07                   | 0.059                  | 0.074                 | 0.084                 | 0.075                 |
| >100B                |                 |                 |                 |                 |                 |                 |                 |                      |                      |                      |                       |                       |                       |                        |                        |                        |                       |                       |                       |
| ChatGPT              | 0.24            | 0.298           | 0.371           | 0.286           | 0.289           | 0.36            | 0.29            | 0.218                | 0.352                | 0.414                | 0.266                 | 0.418                 | 0.487                 | 0.217                  | 0.361                  | 0.428                  | 0.305                 | 0.452                 | 0.517                 |
| GPT-4                | 0.402           | 0.415           | 0.517           | 0.413           | 0.41            | 0.486           | 0.404           | 0.392                | 0.429                | 0.49                 | 0.453                 | 0.496                 | 0.565                 | 0.396                  | 0.434                  | 0.495                  | 0.463                 | 0.506                 | 0.576                 |

## Inference Efficiency

## CuteGPT Examples

| Category                         | Instruction                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | Finetune                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Lora                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Detailed brainstorming           | ['请推荐五本中国古典小说，包含其作品名以及作者名，以表格的形式给出',`<br>`'再在表格中加一列作品的时间呢？']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | ['\| 作品名 \| 作者名 \|`<br>`\| --- \| --- \|`<br>`\| 《红楼梦》 \| 曹雪芹 \|`<br>`\| 《西游记》 \| 吴承恩 \|`<br>`\| 《水浒传》 \| 施耐庵 \|`<br>`\| 《三国演义》 \| 罗贯中 \|`<br>`\| 《聊斋志异》 \| 蒲松龄 \|',`<br>`'\| 作品名 \| 作者名 \| 时间 \|`<br>`\| --- \| --- \| --- \|`<br>`\| 《红楼梦》 \| 曹雪芹 \| 清代 \|`<br>`\| 《西游记》 \| 吴承恩 \| 明代 \|`<br>`\| 《水浒传》 \| 施耐庵 \| 元代 \|`<br>`\| 《三国演义》 \| 罗贯中 \| 明代 \|`<br>`\| 《聊斋志异》 \| 蒲松龄 \| 清代 \|'`<br>`]                                                                                                                                                                                                            | ['\| 作品名 \| 作者名 \|`<br>`\| --- \| --- \|`<br>`\| 《三国演义》 \| 罗贯中 \|`<br>`\| 《水浒传》 \| 施耐庵 \|`<br>`\| 《红楼梦》 \| 曹雪芹、高鹗 \|`<br>`\| 《西游记》 \| 吴承恩 \|`<br>`\| 《儒林外史》 \| 吴敬梓 \|',`<br>`'\| 作品名 \| 作者名 \| 时间 \|`<br>`\| --- \| --- \| --- \|`<br>`\| 《三国演义》 \| 罗贯中 \| 元末明初 \|`<br>`\| 《水浒传》 \| 施耐庵 \| 元末明初 \|`<br>`\| 《红楼梦》 \| 曹雪芹、高鹗 \| 清代中期 \|`<br>`\| 《西游记》 \| 吴承恩 \| 明代 \|`<br>`\| 《儒林外史》 \| 吴敬梓 \| 清代中期 \|`<br>`]                                                                                                                                                                                                        |
| Planning                         | 你是一个知识图谱访问代理，你的任务是编写Python代码，使用内置的Python函数和下面给出的函数来获取用户查询相关的信息：`<br>`1. get_entity_info(entity_aliases)：获取一个实体的百科信息。返回'result'（实体信息或None）和'message'（描述函数调用和结果）。`<br>`2. find_entity_or_value(entity_aliases, relation_aliases)：找到实体或值以回答事实查询。返回'result'（实体名列表或属性值或None）和'message'（描述函数调用和结果）。`<br>`3. find_relationship(entity1_aliases, entity2_aliases)：预测两个实体之间的关系。返回'result'（关系或None）和'message'（描述函数调用和结果）。`<br>`===`<br>`请遵循以下规则：`<br>`1. 你的工作是获取相关知识，而不是直接回答查询。`<br>`2. 只使用内置的Python函数和提供的函数。`<br>`3. 在调用函数时，对实体和关系的别名进行释义和列举候选，按别名频率排序。`<br>`4. 在使用find_entity_or_value时，使用清晰的关系。对于模糊或广泛的关系查询，使用get_entity_info。`<br>`5. 通过富有逻辑的代码处理多步或嵌套的查询。`<br>`6. 以JSON格式响应。`<br>`7. 你需要一步一步思考并给出三个部分的结果：need_knowledge, thought, code。首先，你需要判断该问题是否需要知识。若是，你需要先给出一个想法，规划如何完成该查询。然后，你需要将想法转化为可执行的代码。`<br>`8. 所有函数调用的'messages'都记录在名为'messages'的字符串中，这是search()的返回值。`<br>`9. 在'messages'字符串中添加必要的解释。`<br>`输出格式：`<br>`{`<br>`    "need_knowledge": "<是或否>",`<br>`    "thought": "<你的思考过程>",`<br>`    "code": "def search():\n\tmessages = ''\n\t<你的代码>\n\treturn messages\n",`<br>`}`<br>`===示例===`<br>`Input："提出进化论的科学家是谁？"`<br>`Output：`<br>`{`<br>`    "need_knowledge": "是",`<br>`    "thought": "这个问题想问的是谁提出了进化论，我需要查询进化论的提出者是谁。'提出者'关系可能的表达方式有'提出'、'提出者'、'发现'。",`<br>`    "code": "def search():\n\tmessages = ''\n\tproposer, msg = find_entity_or_value(entity_aliases = ['进化论'], relation_aliases = ['提出', '提出者', '发现'])\n\tmessages += msg\n\treturn messages\n"`<br>`}`<br>`2.`<br>`Input："有哪些科幻小说和《三体》是同一个作者？"`<br>`Output：`<br>`{`<br>`    'need_knowledge': 'yes', `<br>`    'thought': "这个问题想要知道和《三体》是同一个作者的科幻小说都有哪些。首先，我需要找到《三体》的作者，这个关系可能被表达为'作者'、'创作'、'写作'。然后，我需要找到这个作者创作的其他科幻小说，这个关系可能被表达为'作品'、'创作'、'写作'。", `<br>`    'code': "def search():\n\tmessages = ''\n\tauthor, msg = find_entity_or_value(entity_aliases = ['三体'], relation_aliases = ['作者', '创作', '写作'])\n\tmessages += msg\n\tif author:\n\t\tworks, msg = find_entity_or_value(entity_aliases = author, relation_aliases = ['作品', '创作', '写作'])\n\t\tmessages += msg\n\treturn messages\n", `<br>`}`<br>`===`<br>`输入: 《择天记》的男主角是谁？他还有什么代表作品？                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | {`<br>`    "need_knowledge": "是",`<br>`    "thought": "这个问题想问的是《择天记》的男主角是谁，以及他有哪些代表作品。'男主角'关系可能的表达方式有'主角'、'男主角'、'主演'。'代表作品'关系可能的表达方式有'作品'、'代表作品'、'作品名称'。",`<br>`    "code": "def search():`<br>`        messages = ''`<br>`        main_character, msg = find_entity_or_value(entity_aliases = ['择天记'], relation_aliases = ['男主角', '主角', '主演'])       `<br>`        messages += msg `<br>`        representative_works, msg = find_entity_or_value(entity_aliases = main_character, relation_aliases = ['代表作品', '作品', '代表作品', '作品名称'])`<br>`        messages += msg `<br>`        return messages `<br>`",`<br>`} | {`<br>`    "need_knowledge": "是",`<br>`    "thought": "这个问题想问的是《择天记》的男主角是谁，以及他有什么代表作品。首先，我需要找到《择天记》的男主角，这个关系可能被表达 为'主角'、'主演'、'演员'等。其次，我还需要找到他的代表作品，这个关系可能被表达为'作品'、'创作'、'写作'等。",`<br>`    "code": "def search():`<br>`        messages = ''`<br>`        actor, msg = find_entity_or_value(entity_aliases = ['择天记'], relation_aliases = ['主角', '主演', '演员'])`<br>`        messages += msg `<br>`        if actor:`<br>`                works, msg = find_entity_or_value(entity_aliases = actor, relation_aliases = ['作品', '创作', '写作'])`<br>`                messages += msg `<br>`        return messages `<br>`"`<br>`} |
| Complex Extraction               | 从句子中提取公司的基本信息。需要提取公司名称、成立时间、公司类型、资产总额、经营总收入、主要销售区域、主要产品等信息。其中的输出格式为输出格式为字典，包含以下键值对：`<br>`{`<br>`    "公司名称": "",`<br>`    "成立时间": "",`<br>`    "公司类型": "",`<br>`    "资产总额": "",`<br>`    "经营总收入": "",`<br>`    "主要销售区域": "",`<br>`    "主要产品": ""`<br>`}`<br><br>`北京京煤集团有限责任公司是按现代企业制度于2001年初组建的国有独资大型煤炭企业集团。现拥有资产总额149亿元，2008年实现经营总收入93亿元。它所产无烟煤畅销京津、华北、东北、华南及亚、欧、北美、南美四大洲，是中国最大的优质无烟煤生产和出口基地之一。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | {`<br>`    "公司名称": "北京京煤集团有限责任公司",`<br>`    "成立时间": "2001年",`<br>`    "公司类型": "国有企业",`<br>`    "资产总额": "149亿元",`<br>`    "经营总收入": "93亿元",`<br>`    "主要销售区域": "京津、华北、东北、华南及亚、欧、北美、南美四大洲",`<br>`    "主要产品": "无烟煤"`<br>`}                                                                                                                                                                                                                                                                                                                                                                                                                             | {`<br>`    "公司名称": "北京京煤集团有限责任公司",`<br>`    "成立时间": "2001年初",`<br>`    "公司类型": "国有独资大型煤炭企业集团",`<br>`    "资产总额": "149亿元",`<br>`    "经营总收入": "93亿元",`<br>`    "主要销售区域": "京津、华北、东北、华南及亚、欧、北美、南美四大洲",`<br>`    "主要产品": "中国最大的优质无烟煤生产和出口基地之一"`<br>`}                                                                                                                                                                                                                                                                                                                                                                                                  |
| Long text summarization          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| Closed-ended QA                  | 参考这一篇文章里与问题相关的以下3段文本，然后回答后面的问题：`<br>`1:现模型大小的优化，再通过 OpenVINO™的量 化工具和推理引擎，对模型实现 INT8 量化，从而实现模型压缩，以降低模型推理所需的计 算资源和内存带宽，提高模型的推理性能。通过使用中兴 Adlik+第三代英特尔®至强®可扩 展处理器+ OpenVINO™工具套件的组合，可使已完成训练的高精度 AI 模型转换成参数较 小、结构简单、精度基本不下降的 AI 小模型，其性能与大模型接近，模型数据吞吐量更高， 从而实现在不增加 GPU 硬件，大幅减少部署成本的情况下，直接使用 CPU 服务器即可满 足模型的日常推理需求，成功实现降本增效，并使得模型更易部署在算力有限的场景下，比 如自动驾驶车端场景。我们认为此解决方案能够实现 AI 模型推理的降本增效，适用各垂直 领域的 AI 小模型有望加速落地，充分满足不同场景需求。 Adlik 是用于将深度学习模型从训练完成到部署到特定硬件，提供应用服务的 `<br>`2:，充分满足不同场景需求。 Adlik 是用于将深度学习模型从训练完成到部署到特定硬件，提供应用服务的端到端工具链， 其应用目的是为了将模型从研发产 品快速部署到生产应用环境。Adlik 可以和多种推理引 擎协作， 支持多款硬件，提供统一对外推理接口，并提供多种灵活的部署方案。目前谷歌 TensorFLOW，Meta PyTorch 和百度的 PP 飞桨深度学习库都已能够接入 Adlik 架构。随 着 Meta AI SAM 开源图像分割模型的问世，计算机视觉产业或将加速发展。由于 SAM 中 的图像编码器功能必须在 PyTorch 中实现，并需要 GPU 才能进行高效推理，我们认为计 算机视觉产业的发展有望进一步带动对 Meta 深度学习库 PyTorch 以及其他 AI 互联网企业 深度学习库的需求，公司 adlik 软硬整体架构的需求有望提升。 请阅读最后一页免责声明及信息披露 htt `<br>`3: ##### 图 1：SAM 模型设计包含图像编码器、提示编码器和掩码解码器 资料来源：IDC，信达证券研发中心 ➢谷歌、Meta、百度等深度学习库均已接入中兴 Adlik 架构，长期需求有望持续释放 2022 年 12 月 28 日，公司联合英特尔共同发布《英特尔联手中兴优化深度学习模型推理， 实现降本增效》白皮书，本白皮书深入介绍了中兴通讯主导的开源项目 Adlik 如何与英特尔 OpenVINO 工具结合。为解决购买专用 GPU 硬件会大幅增加部署成本，而且应用范围有 限，灵活度较低的问题，中兴通讯通过硬件创新和软件层面的深度优化，在部分场景中，如 果能够直接使用 CPU 来进行推理，将有助于降低成本，提升灵活度，白皮书指出通过中兴 Adlik 可以对 AI 模型进行自动剪枝、蒸馏，实现模型大小的优化，再通过 OpenVINO™的量 化工具和推理引擎，对模型实现 INT8 量化，从而 `<br><br>`问题：Adlik是什么，有什么作用？`<br>`：                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | Adlik是一种用于将深度学习模型从训练完成到部署到特定硬件，提供应用服务的端到端工具链，其应用目的是为了将模型从研发产品快速部署到生产应用环境。Adlik可以和多种推理引擎协作，支持多款硬件，提供统一对外推理接口，并提供多种灵活的部署方案。随着Meta AI SAM开源图像分割模型的问世，计算机视觉产业或将加速发展。由于SAM中的图像编码器功能必须在PyTorch中实现，并需要GPU才能进行高效推理，我们认为计算视觉产业的发展有望进一步带动对Meta深度学习库PyTorch以及其他AI互联网企业的深度学习库的需求，公司adlik软硬整体架构的需求有望提升。                                                                                                                                                                                                                  | Adlik是用于将深度学习模型从训练完成到部署到特定硬件，提供应用服务的端到端工具链，其应用目的是为了将模型从研发产品快速部署到生产应用环境。Adlik可以和多种推理引擎协作，支持多款硬件，提供统一对外推理接口，并提供多种灵活的部署方案。目前谷歌 TensorFlow，Meta PyTorch 和百度的 PP 飞桨深度学习库都已能够接入 Adlik 架构。随着 Meta AI SAM 开源图像分割模型的问世，计算机视觉产业或将加速发展。由于 SAM 中的图像编码器功能必须在 PyTorch 中实现，并需要 GPU 才能进行高效推理，我们认为计算机视觉产业的发展有望进一步带动对 Meta 深度学习库 PyTorch 以及其他 AI 互联网企业深度学习库的需求，公司 Adlik 软硬整体架构的需求有望提升。                                                                                                                                        |
| Long text keywords summarization | 从下文中抽取得到关键词。`<br>`\`\`\``<br>`2022年电线电缆产品质量国家监督抽查 `<br>`情况通报 `<br>` `<br>`2022年，市场监管总局组织电线电缆产品质量国家监督抽查。现将抽查情况通报如下：`<br>`一、基本情况 `<br>`（一）抽查概况。本次抽查检验北京、天津、河北、山西等29个省（区、市）3325家企业生产的3334批次电线电缆，涉及架空绝缘电缆、塑料绝缘控制电缆、挤包绝缘低压电力电缆、挤包绝缘中压电力电缆、额定电压450/750V及以下聚氯乙烯绝缘电线电缆、阻燃聚氯乙烯绝缘电缆等6个品种，分别抽查检验150批次、125批次、1164批次、3批次、1887批次、5批次。共发现93批次产品不合格（详见附件1），抽查不合格率为2.8%，较上次抽查下降0.5个百分点。该产品近3次抽查不合格率分别为5.0%、3.3%、2.8%。`<br>`（二）跟踪抽查情况。本次跟踪抽查到上次抽查不合格企业62家，其中有3家企业产品仍不合格（详见附件2），另59家企业产品合格。`<br>`（三）拒检情况。本次抽查中，广东省中山市东凤镇顶尖电器厂违反《中华人民共和国产品质量法》规定，无正当理由拒绝接受监督抽查。（详见附件3）`<br>`二、抽查结果分析 `<br>`本次抽查重点对电线电缆的绝缘最薄处厚度、导体电阻、单根垂直燃烧试验、成束阻燃性能、绝缘平均厚度、护套平均厚度等24个项目进行检验。其中，绝缘最薄处厚度、导体电阻、单根垂直燃烧试验、成束阻燃性能为安全项目。除单根垂直燃烧试验、绝缘偏心度外，其余项目均有不合格。发现绝缘老化后断裂伸长率有19批次产品不合格，绝缘最薄处厚度有18批次产品不合格，绝缘老化前断裂伸长率有17批次产品不合格，导体电阻、护套热失重试验、绝缘平均厚度、绝缘老化前抗张强度各有12批次产品不合格，绝缘热收缩有11批次产品不合格，绝缘老化后抗张强度有10批次产品不合格，成束阻燃性能有2批次产品不合格。`<br>`经技术机构分析，绝缘最薄处厚度等结构尺寸类项目不合格的主要原因是，生产工艺不当，部分企业在生产时模具配置不合适、挤出工艺控制不精确；导体电阻不合格的主要原因是，部分企业拉丝、束丝或绞制过程控制不符合规定；成束阻燃性能不合格的主要原因是，阻燃原材料存在质量问题；绝缘老化前抗张强度、绝缘老化前断裂伸长率、绝缘老化后抗张强度、绝缘老化后断裂伸长率、绝缘热收缩、护套热失重试验等机械性能项目不合格的主要原因是，绝缘和护套的原材料不符合要求，部分企业挤塑、交联等工艺控制水平不过关。 `<br>`以上抽查主要涉及河北省、浙江省、江苏省、河南省、广东省、山东省、安徽省等产业聚集区企业生产的产品，分别抽查检验784批次、434批次、417批次、241批次、239批次、225批次、210批次，抽查不合格率分别为1.4%、3.2%、3.1%、3.3%、4.6%、1.8%、3.8%。`<br>`三、有关要求 `<br>`针对本次产品质量国家监督抽查发现的问题，各有关省级市场监管部门要做好如下工作：`<br>`（一）强化抽查结果处理。按照《产品质量法》、《产品质量监督抽查管理暂行办法》等规定，做好监督抽查结果处理工作。对监督抽查发现的不合格产品，依法采取查封、扣押等措施，严禁企业出厂销售，采取有效措施控制产品质量安全风险。对不合格企业，尤其是上次抽查不合格企业，进一步明确整改要求，严格督促落实整改措施，及时组织复查。对涉嫌犯罪的，及时移送司法机关。将严重违法失信企业，依法纳入严重违法失信企业名单管理。结果处理情况要及时录入e-CQS系统。总局将强化跟踪督办，视情通报各地处理结果情况。`<br>`（二）开展质量专项整治。江苏省、浙江省、安徽省、河南省、广东省等生产企业聚集区市场监管部门，要开展专项整治，加大辖区内重点企业监督检查力度，综合运用多种手段，保持质量监管高压态势，严肃处理质量违法行为，提升质量安全水平。`<br>`（三）督促落实主体责任。将本次监督抽查不合格产品情况通报相关地方政府及部门，采取有力措施，督促不合格产品企业落实产品质量安全主体责任，严格按照标准依法组织生产销售，保障产品质量安全。`<br>`（四）加强质量技术帮扶。组织有关行业组织和技术机构，帮助企业深入查找原因，提出改进措施和解决方案，促进行业质量水平提高。`<br>`\`\`\` | 电线电缆;产品质量;国家监督抽查;不合格产品;抽查结果;跟踪抽查;质量专项整治;主体责任;质量技术帮扶                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | 抽查;电线电缆;产品质量                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| Self-correction                  | ['刘德华于2008年6月注册结婚的太太是谁?',`<br>`'再想想呢？']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | ['谢天华',`<br>`'刘德华于2008年6月注册结婚的太太是朱丽倩。']                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | ['刘德华于2008年6月注册结婚的太太是朱丽倩。',`<br>`'刘德华于2008年6月注册结婚的太太是朱丽倩。']使用方式                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |

## Local Deployment

### Install Dependencies

```bash
conda create -n cutegpt python=3.7
conda activate cutegpt
pip install -r requirements.txt 
```

By the way, please continue with the above format, translate the following markdown text into English, wrap all your answers with ```, so I can copy them directly.

### Usage Example

```python
from transformers import LlamaForCausalLM, LlamaTokenizer
from peft import PeftModel
import torch
```

* The prompt template for inference

```python
overall_instruction = "你是复旦大学知识工场实验室训练出来的语言模型CuteGPT。给定任务描述，请给出对应请求的回答。\n"
def generate_prompt(query, history, input=None):
    prompt = overall_instruction
    for i, (old_query, response) in enumerate(history):
        # Multi-turn dialogue needs to be consistent with training
        prompt += "Q: {}\nA: {}\n".format(old_query, response)
    prompt += "Q: {}\nA: ".format(query)
    return prompt
```

* Load model, tokenizer, here we use lora version of checkpoint, 8bit quantization

```python
model_name = "XuYipei/kw-cutegpt-13b-base"
LORA_WEIGHTS = "Abbey4799/kw-cutegpt-13b-ift-lora"
tokenizer = LlamaTokenizer.from_pretrained(LORA_WEIGHTS)
model = LlamaForCausalLM.from_pretrained(
    model_name,
    load_in_8bit=True,
    torch_dtype=torch.float16,
    device_map="auto",
)
model.eval()
model = PeftModel.from_pretrained(model, LORA_WEIGHTS)
device = torch.device("cuda")
```

* Inference

```python
history = []
queries = ['请推荐五本名著，依次列出作品名、作者','再来三本呢？']
memory_limit = 3 # the number of (query, response) to remember
for query in queries:
    prompt = generate_prompt(query, history)
    print(prompt)

    input_ids = tokenizer(prompt, return_tensors="pt", padding=False, truncation=False, add_special_tokens=False)
    input_ids = input_ids["input_ids"].to(device)

    with torch.no_grad():
        outputs=model.generate(
                input_ids=input_ids,
                top_p=0.8,
                top_k=50,
                repetition_penalty=1.1,
                max_new_tokens = 256,
                early_stopping = True,
                eos_token_id = tokenizer.convert_tokens_to_ids('<s>'),
                pad_token_id = tokenizer.eos_token_id,
                min_length = input_ids.shape[1] + 1
        )
    s = outputs[0][input_ids.shape[1]:]
    response=tokenizer.decode(s)
    response = response.replace('<s>', '').replace('<end>', '').replace('</s>', '')
    print(response)
    history.append((query, response))
    history = history[-memory_limit:]
```

You can run the following script directly for inference:

```bash
CUDA_VISIBLE_DEVICES=0 python inference.py
```

## Fine-tuning

### Data Format

The data is stored in `.pkl` format, and you can use the following code to view the data:

```python
import pickle
import random
file = 'data/test/ift_data.pkl'
with open(file, "rb") as f:
    datas = pickle.load(f)
print(len(datas))
print(random.sample(datas,3))
```

The data is stored in a two-dimensional array, where `len(datas)` represents the number of samples, and `len(data[i])` represents the number of dialogue turns for the i-th sample. Each dialogue turn consists of three key-value pairs: `instruction`, `input`, and `output`. Here is an example:

```python
[[{'instruction': '请帮我生成一首诗。', 'input': '', 'output': '好的，请给我一些关键词来启发诗歌的创作。'},
  {'instruction': '月亮、海浪、夜晚。',
   'input': '',
   'output': '心中的孤独由天空掩盖，\n夜幕笼罩下，海浪轻扬，\n月光照亮着沙滩，\n让我不再孤单。'}],
 [{'instruction': '根据给定的数据集，训练一个能够对垃圾邮件进行分类的模型。\n提供垃圾邮件和非垃圾邮件两类的数据集。',
   'input': '',
   'output': '要训练一个能...'}]]
```

### Fine-tuning Code

Preprocess the data, concatenate it into the format of multi-turn dialogues, and encode it to obtain `input_ids`, then save it.

```bash
python code/convert_data.py \
    --tokenizer ziqingyang/chinese-llama-lora-7b \
    --max_length 2048 \
    --out_data_path data/test/
```

Train the model

```bash
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 deepspeed --master_port 12932 code/finetune.py \
    --save_steps 2000 \
    --max_epoches 4 \
    --save_name llama_lora \
    --model_path XuYipei/kw-cutegpt-13b-base \
    --dataset_type DatasetIds \
    --data_path data/test/llama_ift_data_ids.pkl \
    --max_length 2048 \
    --use_flash_attention
```

Parameter Explanation

* `model_path`: Path to the `base` model.
* `dataset_type`: Defines the `dataset` class used for data encapsulation, defined in `code/dataset.py`.
* `use_flash_attention`: Whether to use flash attention to speed up training and reduce GPU memory consumption.
* `load_lora`: Whether to load the Lora checkpoint for continued training. If `load_lora==True`, define the path to the Lora checkpoint in `load_lora_path`.

Refer to `code/config.py` for specific deepspeed parameters (e.g., learning rate, batch size) and Lora parameters (e.g., Lora rank).

You can directly run the following command to start training:

```
bash finetune.sh
```
